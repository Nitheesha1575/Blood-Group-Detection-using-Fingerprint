
import numpy as numpy
import pandas as pandas
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        os.path.join(dirname,filename)
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from collections import Counter
import numpy as numpy
import os
import shutil
from sklearn.utils import resample
from tensorflow.keras.preprocessing.image import load_img, img_to_array, save_img
from tensorflow.keras.preprocessing import image_dataset_from_directory
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import pandas as pd
dataset_path=r"C:\Users\palle\OneDrive\Desktop\IPD-4\Blood-group-prediction\dataset_blood_group"
BATCH_SIZE = 32
dataset = image_dataset_from_directory(
    dataset_path,
    labels="inferred",
    label_mode="int",
    image_size=(64, 64),
    batch_size=BATCH_SIZE,
    shuffle=True
)
Found 6000 files belonging to 8 classes.
class_names=dataset.class_names
class_counts = Counter()
for _, labels in dataset.unbatch():
    class_counts[int(labels.numpy())] += 1
print('Class Distribution:')
for i,count in class_counts.items():
    print(f"{class_names[i]}: {count}")
Class Distribution:
AB-: 761
A+: 565
O-: 712
O+: 852
B+: 652
AB+: 708
A-: 1009
B-: 741
import matplotlib.pyplot as plt
def plot_class_distribution(class_names,class_counts):
    classes = [class_names[i] for i in class_counts.keys()]
    classes = [class_counts[i] for i in class_counts.keys()]
plot_class_distribution(class_names, class_counts)
import matplotlib.pyplot as plt

# Define the class names (blood groups)
class_names = ['A-', 'AB-', 'O+', 'O-', 'B-', 'AB+', 'B+', 'A+']

# Corresponding count of images for each class
count = [1009, 761, 852, 712, 741, 708, 652, 565]

# Create bar chart
plt.figure(figsize=(8, 5))  # Set figure size
plt.bar(class_names, count, color='skyblue')  # Bar chart with color
plt.xlabel("Blood Group Classes")
plt.ylabel("Number of Images")
plt.title("Dataset Class Distribution")

# Annotate each bar with its value
for i, v in enumerate(count):
    plt.text(i, v + 20, str(v), ha='center', fontsize=10)

plt.show()

import matplotlib.pyplot as plt
max_count = max(class_counts.values())
# Sample data
class_names = ["A+", "A-", "B+", "B-", "O+", "O-", "AB+", "AB-"]
count = [1009, 761, 852, 712, 741, 708, 652, 565]

plt.figure(figsize=(8, 5))  # Set figure size
bars = plt.bar(class_names, max_count, color='skyblue')

# Adding text on top of each bar
for bar in bars:
    yval = bar.get_height()  # Get bar height
    plt.text(bar.get_x() + bar.get_width()/2, yval, str(yval), 
             ha='center', va='bottom', fontsize=12, fontweight='bold')

# Labels and title
plt.xlabel("Blood Group Classes")
plt.ylabel("Number of Images")
plt.title("Dataset Class Distribution")

# Show the plot
plt.show()

max_count = max(class_counts.values())
def oversample_class(class_id, count, max_count):
    unbatched_dataset = dataset.unbatch()
    class_dataset = unbatched_dataset.filter(lambda img, lbl: tf.equal(lbl, class_id))
    repeat_factor = max_count // count + (max_count % count > 0)
    return class_dataset.repeat(repeat_factor).take(max_count)
balanced_datasets = []
for class_id, count in class_counts.items():
    balanced_datasets.append(oversample_class(class_id, count, max_count))
balanced_dataset = tf.data.experimental.sample_from_datasets(balanced_datasets)
balanced_class_counts = Counter([int(lbl.numpy()) for _, lbl in balanced_dataset])
plot_class_distribution(class_names, balanced_class_counts)
balanced_dataset = balanced_dataset.batch(BATCH_SIZE,drop_remainder=True)
plt.show()
for sample in balanced_dataset.take(10):
    print(sample[0].shape)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
(32, 64, 64, 3)
balanced_dataset_unbatched = balanced_dataset.unbatch()
dataset_size = sum(1 for _ in balanced_dataset_unbatched)
print(f"Total dataset size: {dataset_size}")
Total dataset size: 8064
# Unbatch the dataset to get individual samples
balanced_dataset_unbatched = balanced_dataset.unbatch()

# Compute the total dataset size
dataset_size = sum(1 for _ in balanced_dataset_unbatched)

# Define split ratios
train_ratio = 0.7
val_ratio = 0.20
test_ratio = 0.10

# Compute exact dataset sizes
train_size = int(train_ratio * dataset_size)
val_size = int(val_ratio * dataset_size)
#test_size = dataset_size - (train_size + val_size)  # Ensure exact split
"""
print(f"Total dataset size: {dataset_size}")
print(f"Expected splits -> Train: {train_size}, Val: {val_size}, Test: {test_size}")
"""
# Re-create the dataset after computing size
balanced_dataset_unbatched = balanced_dataset.unbatch()  # Reinitialize iterator

# Split dataset correctly
train_dataset = balanced_dataset_unbatched.take(train_size)
val_test_dataset= balanced_dataset_unbatched.skip(train_size)
val_dataset = val_test_dataset.take(val_size)
#test_test_dataset= balanced_dataset_unbatched.skip(val_size)
test_dataset = val_test_dataset.skip(val_size)  # Remaining samples go to test

# Batch datasets correctly
train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)
val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)
test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)

# Compute final dataset sizes
train_batch_count = sum(1 for _ in train_dataset)
val_batch_count = sum(1 for _ in val_dataset)
test_batch_count = sum(1 for _ in test_dataset)

print(f"Final dataset sizes after batching:")
print(f"Training dataset size: {train_batch_count * BATCH_SIZE}")
print(f"Validation dataset size: {val_batch_count * BATCH_SIZE}")
print(f"Testing dataset size: {test_batch_count * BATCH_SIZE}")
Final dataset sizes after batching:
Training dataset size: 5632
Validation dataset size: 1600
Testing dataset size: 800
def create_high_accuracy_model():
    model = tf.keras.models.Sequential([
        tf.keras.layers.Conv2D(32, (3,3), activation='relu', padding='same', input_shape=(64,64,3)),  # Change from (64,64,3) to (224,224,3)
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.3),

        tf.keras.layers.Conv2D(64, (3,3), activation='relu', padding='same',input_shape=(64,64,3)),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.4),

        tf.keras.layers.Conv2D(128, (3,3), activation='relu', padding='same',input_shape=(64,64,3)),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.4),

        tf.keras.layers.Conv2D(256, (3,3), activation='relu', padding='same',input_shape=(64,64,3)),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.4),

        tf.keras.layers.Conv2D(512, (3,3), activation='relu', padding='same',input_shape=(64,64,3)),
        tf.keras.layers.MaxPooling2D(2,2),
        tf.keras.layers.Dropout(0.4),

        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(1024, activation='relu'),
        tf.keras.layers.Dropout(0.5),

        tf.keras.layers.Dense(10, activation='softmax')  # Assuming 10 classes
    ])

    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    return model

# Create a new model with updated input shape
create_high_acc_model = create_high_accuracy_model()
from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=3,
    verbose=1,
    min_lr=1e-6
)

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=5,
    verbose=1,
    restore_best_weights=True
)
history_high_acc = create_high_acc_model.fit(
    train_dataset,
    validation_data = val_dataset,
    epochs=50,
    callbacks=[reduce_lr, early_stop]
)
Epoch 1/50
176/176 [==============================] - 161s 901ms/step - loss: 7.9334 - accuracy: 0.1364 - val_loss: 2.2384 - val_accuracy: 0.1206
Epoch 2/50
176/176 [==============================] - 228s 1s/step - loss: 2.0698 - accuracy: 0.1653 - val_loss: 2.1433 - val_accuracy: 0.2031
Epoch 3/50
176/176 [==============================] - 250s 1s/step - loss: 1.8335 - accuracy: 0.2955 - val_loss: 1.8594 - val_accuracy: 0.3644
Epoch 4/50
176/176 [==============================] - 146s 823ms/step - loss: 1.4725 - accuracy: 0.4402 - val_loss: 1.9231 - val_accuracy: 0.1975
Epoch 5/50
176/176 [==============================] - 149s 840ms/step - loss: 1.2422 - accuracy: 0.5321 - val_loss: 1.5948 - val_accuracy: 0.4375
Epoch 6/50
176/176 [==============================] - 166s 937ms/step - loss: 1.0902 - accuracy: 0.5822 - val_loss: 1.5065 - val_accuracy: 0.5150
Epoch 7/50
176/176 [==============================] - 221s 1s/step - loss: 1.0467 - accuracy: 0.6051 - val_loss: 1.3215 - val_accuracy: 0.6331
Epoch 8/50
176/176 [==============================] - 214s 1s/step - loss: 0.9347 - accuracy: 0.6566 - val_loss: 1.2406 - val_accuracy: 0.6862
Epoch 9/50
176/176 [==============================] - 159s 903ms/step - loss: 0.8575 - accuracy: 0.6928 - val_loss: 1.0689 - val_accuracy: 0.7812
Epoch 10/50
176/176 [==============================] - 158s 891ms/step - loss: 0.8334 - accuracy: 0.6992 - val_loss: 0.9514 - val_accuracy: 0.7663
Epoch 11/50
176/176 [==============================] - 178s 1s/step - loss: 0.7808 - accuracy: 0.7186 - val_loss: 1.2683 - val_accuracy: 0.5719
Epoch 12/50
176/176 [==============================] - 265s 1s/step - loss: 0.7223 - accuracy: 0.7338 - val_loss: 0.9925 - val_accuracy: 0.7100
Epoch 13/50
176/176 [==============================] - 148s 837ms/step - loss: 0.7091 - accuracy: 0.7422 - val_loss: 0.8341 - val_accuracy: 0.7788
Epoch 14/50
176/176 [==============================] - 157s 886ms/step - loss: 0.6608 - accuracy: 0.7631 - val_loss: 0.7353 - val_accuracy: 0.8331
Epoch 15/50
176/176 [==============================] - 142s 803ms/step - loss: 0.6545 - accuracy: 0.7635 - val_loss: 0.8324 - val_accuracy: 0.7719
Epoch 16/50
176/176 [==============================] - 140s 789ms/step - loss: 0.6142 - accuracy: 0.7766 - val_loss: 0.6551 - val_accuracy: 0.8269
Epoch 17/50
176/176 [==============================] - 146s 823ms/step - loss: 0.6333 - accuracy: 0.7658 - val_loss: 0.7091 - val_accuracy: 0.8044
Epoch 18/50
176/176 [==============================] - 160s 907ms/step - loss: 0.6220 - accuracy: 0.7713 - val_loss: 0.6407 - val_accuracy: 0.8163
Epoch 19/50
176/176 [==============================] - 149s 844ms/step - loss: 0.6100 - accuracy: 0.7795 - val_loss: 0.7058 - val_accuracy: 0.7844
Epoch 20/50
176/176 [==============================] - 161s 910ms/step - loss: 0.6015 - accuracy: 0.7761 - val_loss: 0.6633 - val_accuracy: 0.8294
Epoch 21/50
176/176 [==============================] - 205s 1s/step - loss: 0.6193 - accuracy: 0.7711 - val_loss: 0.9027 - val_accuracy: 0.7013

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 22/50
176/176 [==============================] - 259s 1s/step - loss: 0.5261 - accuracy: 0.8049 - val_loss: 0.5439 - val_accuracy: 0.8487
Epoch 23/50
176/176 [==============================] - 197s 1s/step - loss: 0.4780 - accuracy: 0.8194 - val_loss: 0.5055 - val_accuracy: 0.8569
Epoch 24/50
176/176 [==============================] - 168s 953ms/step - loss: 0.4543 - accuracy: 0.8322 - val_loss: 0.5346 - val_accuracy: 0.8500
Epoch 25/50
176/176 [==============================] - 141s 796ms/step - loss: 0.4618 - accuracy: 0.8192 - val_loss: 0.5001 - val_accuracy: 0.8494
Epoch 26/50
176/176 [==============================] - 147s 830ms/step - loss: 0.4522 - accuracy: 0.8265 - val_loss: 0.5802 - val_accuracy: 0.8075
Epoch 27/50
176/176 [==============================] - 172s 962ms/step - loss: 0.4278 - accuracy: 0.8398 - val_loss: 0.4729 - val_accuracy: 0.8575
Epoch 28/50
176/176 [==============================] - 163s 920ms/step - loss: 0.4592 - accuracy: 0.8175 - val_loss: 0.5342 - val_accuracy: 0.8481
Epoch 29/50
176/176 [==============================] - 149s 841ms/step - loss: 0.4465 - accuracy: 0.8303 - val_loss: 0.4304 - val_accuracy: 0.8781
Epoch 30/50
176/176 [==============================] - 160s 903ms/step - loss: 0.4306 - accuracy: 0.8350 - val_loss: 0.4540 - val_accuracy: 0.8550
Epoch 31/50
176/176 [==============================] - 153s 864ms/step - loss: 0.4336 - accuracy: 0.8324 - val_loss: 0.4659 - val_accuracy: 0.8631
Epoch 32/50
176/176 [==============================] - 166s 941ms/step - loss: 0.4216 - accuracy: 0.8381 - val_loss: 0.4861 - val_accuracy: 0.8606

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 33/50
176/176 [==============================] - 151s 853ms/step - loss: 0.3958 - accuracy: 0.8489 - val_loss: 0.4906 - val_accuracy: 0.8581
Epoch 34/50
176/176 [==============================] - 174s 982ms/step - loss: 0.3779 - accuracy: 0.8501 - val_loss: 0.3842 - val_accuracy: 0.8969
Epoch 35/50
176/176 [==============================] - 172s 973ms/step - loss: 0.3616 - accuracy: 0.8574 - val_loss: 0.3832 - val_accuracy: 0.8875
Epoch 36/50
176/176 [==============================] - 180s 1s/step - loss: 0.3675 - accuracy: 0.8558 - val_loss: 0.4428 - val_accuracy: 0.8656
Epoch 37/50
176/176 [==============================] - 186s 1s/step - loss: 0.3440 - accuracy: 0.8723 - val_loss: 0.3537 - val_accuracy: 0.8963
Epoch 38/50
176/176 [==============================] - 154s 872ms/step - loss: 0.3734 - accuracy: 0.8516 - val_loss: 0.3876 - val_accuracy: 0.8981
Epoch 39/50
176/176 [==============================] - 160s 898ms/step - loss: 0.3485 - accuracy: 0.8667 - val_loss: 0.4019 - val_accuracy: 0.8794
Epoch 40/50
176/176 [==============================] - 134s 756ms/step - loss: 0.3364 - accuracy: 0.8661 - val_loss: 0.3744 - val_accuracy: 0.8850

Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 41/50
176/176 [==============================] - 137s 773ms/step - loss: 0.3179 - accuracy: 0.8786 - val_loss: 0.3619 - val_accuracy: 0.8919
Epoch 42/50
176/176 [==============================] - 137s 775ms/step - loss: 0.3247 - accuracy: 0.8729 - val_loss: 0.4254 - val_accuracy: 0.8550
Restoring model weights from the end of the best epoch.
Epoch 00042: early stopping
high_acc_eval = create_high_acc_model.evaluate(val_dataset)    
print(f"High Accuracy Model - Loss: {high_acc_eval[0]}, Accuracy: {high_acc_eval[1]}")
50/50 [==============================] - 45s 236ms/step - loss: 0.3555 - accuracy: 0.8900
High Accuracy Model - Loss: 0.3554893434047699, Accuracy: 0.8899999856948853
import matplotlib.pyplot as plt

plt.plot(history_high_acc.history['loss'], label='Train Loss')
plt.plot(history_high_acc.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

def plot_accuracy(history):
    import matplotlib.pyplot as plt  # Ensure Matplotlib is imported
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])  # Avoids errors if val_accuracy is missing
    plt.title('Model Accuracy')
    plt.ylabel('Accuracy')
    plt.xlabel('Epoch')
    plt.legend(['Train', 'Validation'], loc='upper left')
    plt.show()

plot_accuracy(history_high_acc)  # Call outside the function

import tensorflow as tf

test_data_path = r"C:\Users\palle\OneDrive\Desktop\IPD-4\Blood-group-prediction\dataset_blood_group"

test_dataset = tf.keras.preprocessing.image_dataset_from_directory(
    test_data_path,
    image_size=(64,64),  # Adjust based on your model input size
    #label_mode="categorical",
    batch_size=32,
    shuffle=False
)
"""
dataset = image_dataset_from_directory(
    dataset_path,
    labels="inferred",
    label_mode="categorical",  # One-hot encoding
    image_size=(64, 64),
    batch_size=BATCH_SIZE,
    shuffle=True
)

"""
Found 6000 files belonging to 8 classes.
'\ndataset = image_dataset_from_directory(\n    dataset_path,\n    labels="inferred",\n    label_mode="categorical",  # One-hot encoding\n    image_size=(64, 64),\n    batch_size=BATCH_SIZE,\n    shuffle=True\n)\n\n'
y_true = []
y_pred = []
for images, labels in test_dataset:
    predictions = create_high_acc_model.predict(images)
    predicted_labels = np.argmax(predictions, axis=1)
    y_true.extend(labels.numpy())
    y_pred.extend(predicted_labels)
#class_names = ['A+', 'A-', 'O-', 'O+', 'AB+', 'B+', 'AB-', 'B-']
y_true = np.array(y_true)
y_pred = np.array(y_pred)
report = classification_report(y_true,y_pred,target_names=class_names)
print("Classification Report")
print(report)

conf_matrix = confusion_matrix(y_true,y_pred)

plt.figure(figsize=(8,6))
sns.heatmap(conf_matrix, annot=True,fmt='d',cmap='Blues',xticklabels=class_names,yticklabels=class_names)
plt.title('Configuration Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()
Classification Report
              precision    recall  f1-score   support

          A+       0.95      0.95      0.95       565
          A-       0.89      0.85      0.87      1009
          B+       0.93      0.94      0.93       708
          B-       0.94      0.83      0.88       761
          O+       0.90      0.93      0.91       652
          O-       0.80      0.99      0.89       741
         AB+       0.90      0.90      0.90       852
         AB-       0.93      0.85      0.89       712

    accuracy                           0.90      6000
   macro avg       0.91      0.90      0.90      6000
weighted avg       0.90      0.90      0.90      6000


high_acc_model = create_high_acc_model  # Assign trained model

high_acc_model.save('model.h5')
print("Model saved.")
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-8-6a1e5ced1f2b> in <module>
----> 1 high_acc_model = create_high_acc_model  # Assign trained model
      2 
      3 high_acc_model.save('model.h5')
      4 print("Model saved.")

NameError: name 'create_high_acc_model' is not defined
high_acc_model.save('model.h5')
print("Model saved as HDF5 format")
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-5-199f6671a407> in <module>
----> 1 high_acc_model.save('model.h5')
      2 print("Model saved as HDF5 format")

NameError: name 'high_acc_model' is not defined
high_acc_model.save('model.h5')
print("Model saved as HDF5 format")
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-9-199f6671a407> in <module>
----> 1 high_acc_model.save('model.h5')
      2 print("Model saved as HDF5 format")

NameError: name 'high_acc_model' is not defined
 
